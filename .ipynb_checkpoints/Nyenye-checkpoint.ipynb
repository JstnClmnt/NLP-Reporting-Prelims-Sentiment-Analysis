{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"imdb_master.csv\",encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(\"neg\", 0)\n",
    "df=df.replace(\"pos\", 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=df[df[\"type\"]==\"train\"]\n",
    "testdf=df[df[\"type\"]==\"test\"]\n",
    "traindf=traindf[[\"review\",\"label\"]]\n",
    "testdf=testdf[[\"review\",\"label\"]]\n",
    "print(len(traindf))\n",
    "print(len(testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=traindf[\"review\"].values\n",
    "y_train=traindf[\"label\"].values\n",
    "X_test=testdf[\"review\"].values\n",
    "y_test=testdf[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set([])\n",
    "for s in X_train:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "total_reviews=len(traindf)+len(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Model Parameters\n",
    "cbow = 0\n",
    "skipgram = 1\n",
    "EMB_DIM = 300 #more dimensions, more computationally expensive to train\n",
    "min_word_count = 1\n",
    "workers = multiprocessing.cpu_count() #based on computer cpu count\n",
    "context_size = 7\n",
    "downsampling = 1e-3\n",
    "learning_rate = 0.025 #initial learning rate\n",
    "min_learning_rate = 0.025 #fixated learning rate\n",
    "num_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(\n",
    "    sg = skipgram,\n",
    "    hs = 1, #hierarchical softmax\n",
    "    size = EMB_DIM,\n",
    "    min_count = min_word_count, \n",
    "    workers = workers,\n",
    "    window = context_size, \n",
    "    sample = downsampling, \n",
    "    alpha = learning_rate, \n",
    "    min_alpha = min_learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.build_vocab(X_train)\n",
    "w2v.train(X_train,epochs=10,total_examples=w2v.corpus_count)\n",
    "words = list(w2v.wv.vocab)\n",
    "print('Vocabulary size: %d' % len(words))\n",
    "# save model in ASCII (word2vec) format\n",
    "filename = 'embedding_word2vec.txt'\n",
    "w2v.wv.save_word2vec_format(filename, binary=False)\n",
    "\n",
    "embeddings_index={}\n",
    "f=open(os.path.join('','embedding_word2vec.txt '),encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:])\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_X, test_sentences_X = [], []\n",
    "\n",
    "num_words=len(word2index)+1\n",
    "embedding_matrix=np.zeros((num_words,EMB_DIM))\n",
    "print(word2index)\n",
    "for word,i in word2index.items():\n",
    "    if i>num_words:\n",
    "        continue\n",
    "    embedding_vector=embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector\n",
    "\n",
    "for s in X_train:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    "    \n",
    "for s in X_test:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
